{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 12 - Neural Networks image recognition\n",
    "Use both MLNN and the ConvNet to solve the following problem.\n",
    "\n",
    "1. Add random noise (i.e. `np.random.normal`) to the images in training and testing. Make sure each image gets a different noise feature added to it. Inspect by printing out an image. \n",
    "2. Compare the loss/accuracy (train, val) after N epochs for both MLNN and ConvNet with and without noise. \n",
    "3. Vary the amount of noise (multiply `np.random.normal` by a factor) and keep track of the accuracy and loss (for training and validation) and plot these results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note on assignment:  \n",
    "Because of time constraints, I was not able to complete the 3rd prompt with more varied amounts of noise or run models to find ideal parameters. The processing for both the MLNN and CNNs on my laptop were very time intensive.  I was also running into multiple error codes which I had trouble remedying directly (and thus had to create multiple jupyter notebooks with different kernels)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks - Image Recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop, Nadam, Adadelta\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as  plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Results for Parts 1-3\n",
    "Compare the loss/accuracy (train, val) after N epochs for both MLNN and ConvNet with and without noise. \n",
    "\n",
    "The table below shows the results of the various models.  You can see that generally the Convolutional Neural Networks performed better than the Multi-layer Neural Networks even against noisy data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Scores\n",
    "\n",
    "**Model Type**&nbsp;   || *No Noise* || *With Noise* || *With Amplified Noise* ||\n",
    "\n",
    "**MLNN**&emsp;&emsp;&emsp;   || &nbsp;     98.5%&nbsp;    &nbsp;      ||   &nbsp;    81.2% &nbsp; &nbsp;         || &nbsp;       80.2%              ||\n",
    "\n",
    "**CNN**&emsp;&emsp;&emsp;&ensp;&nbsp;   ||  &nbsp;    99.2% &nbsp; &nbsp;        ||  &nbsp;     97.5% &nbsp; &nbsp;         || &nbsp;       97.4%              ||\n",
    "\n",
    "\n",
    "\n",
    "### Loss Scores\n",
    "\n",
    "**Model Type**&nbsp;   || *No Noise* || *With Noise* || *With Amplified Noise* ||\n",
    "\n",
    "**MLNN**&emsp;&emsp;&emsp;   || &nbsp; &nbsp;    0.11&nbsp;    &nbsp;&nbsp;      ||   &nbsp;  &nbsp;  0.92 &nbsp;&nbsp; &nbsp; &nbsp;        || &nbsp;  &nbsp;&nbsp;     0.82  &nbsp;&nbsp;            ||\n",
    "\n",
    "**CNN**&emsp;&emsp;&emsp;&ensp;&nbsp;  || &nbsp; &nbsp;    0.03&nbsp;    &nbsp;  &nbsp;    ||   &nbsp;  &nbsp;  0.09 &nbsp;&nbsp; &nbsp; &nbsp;         || &nbsp;  &nbsp;&nbsp;     0.08  &nbsp;&nbsp;            ||\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: With noise (np.random.normal)\n",
    "1. Add random noise (i.e. `np.random.normal`) to the images in training and testing. Make sure each image gets a different noise feature added to it. Inspect by printing out an image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Neural Network\n",
    "Trains a simple deep NN on the MNIST dataset.\n",
    "Previous model gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add in the noise by multiplying by np.random.normal\n",
    "\n",
    "x2_train = x_train * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
    "x2_test = x_test * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) train samples\n",
      "(10000, 784) test samples\n"
     ]
    }
   ],
   "source": [
    "x2_train = x2_train.reshape(60000, 784)\n",
    "x2_test = x2_test.reshape(10000, 784)\n",
    "\n",
    "x2_train = x2_train.astype('float32')\n",
    "x2_test = x2_test.astype('float32')\n",
    "x2_train /= 255\n",
    "x2_test /= 255\n",
    "print(x2_train.shape, 'train samples')\n",
    "print(x2_test.shape, 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noAg/EBThB4Ii/EBQhB8I6v8BOGqMLFMSeisAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x122151c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check out an image from training set\n",
    "plt.imshow(x2_train[0].reshape(28,28)) #need to add in .reshape to the shape of the matrix to plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x124e79748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check out an image from test set\n",
    "plt.imshow(x2_test[0].reshape(28,28)) #need to add in .reshape to the shape of the matrix to plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** The images above show a very pixelated/grainy/noisy image.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 932,362\n",
      "Trainable params: 932,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 48s - loss: 1.8535 - acc: 0.3137 - val_loss: 1.3265 - val_acc: 0.5099\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 47s - loss: 1.1141 - acc: 0.5953 - val_loss: 0.9588 - val_acc: 0.6581\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 50s - loss: 0.8004 - acc: 0.7149 - val_loss: 0.8161 - val_acc: 0.7143\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 47s - loss: 0.6264 - acc: 0.7802 - val_loss: 0.8022 - val_acc: 0.7344\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 41s - loss: 0.5094 - acc: 0.8204 - val_loss: 0.7363 - val_acc: 0.7550\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 40s - loss: 0.4301 - acc: 0.8503 - val_loss: 0.7353 - val_acc: 0.7677\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 42s - loss: 0.3682 - acc: 0.8744 - val_loss: 0.7281 - val_acc: 0.7736\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 44s - loss: 0.3196 - acc: 0.8896 - val_loss: 0.7532 - val_acc: 0.7796\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 55s - loss: 0.2817 - acc: 0.9026 - val_loss: 0.7757 - val_acc: 0.7775\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 60s - loss: 0.2481 - acc: 0.9141 - val_loss: 0.7952 - val_acc: 0.7805\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 46s - loss: 0.2237 - acc: 0.9230 - val_loss: 0.7687 - val_acc: 0.7886\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 47s - loss: 0.2036 - acc: 0.9316 - val_loss: 0.7704 - val_acc: 0.7905\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 52s - loss: 0.1864 - acc: 0.9360 - val_loss: 0.8234 - val_acc: 0.7927\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 47s - loss: 0.1718 - acc: 0.9409 - val_loss: 0.8189 - val_acc: 0.7977\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 48s - loss: 0.1642 - acc: 0.9434 - val_loss: 0.8242 - val_acc: 0.7950\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 51s - loss: 0.1483 - acc: 0.9491 - val_loss: 0.8543 - val_acc: 0.7974\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 48s - loss: 0.1447 - acc: 0.9517 - val_loss: 0.8694 - val_acc: 0.7910\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 57s - loss: 0.1407 - acc: 0.9518 - val_loss: 0.8322 - val_acc: 0.7953\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 51s - loss: 0.1319 - acc: 0.9558 - val_loss: 0.8625 - val_acc: 0.7997\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 53s - loss: 0.1268 - acc: 0.9568 - val_loss: 0.8459 - val_acc: 0.7985\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 50s - loss: 0.1233 - acc: 0.9582 - val_loss: 0.8444 - val_acc: 0.8088\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 49s - loss: 0.1165 - acc: 0.9608 - val_loss: 0.8608 - val_acc: 0.8044\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 60s - loss: 0.1109 - acc: 0.9634 - val_loss: 0.8889 - val_acc: 0.8105\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 56s - loss: 0.1069 - acc: 0.9646 - val_loss: 0.8973 - val_acc: 0.8089\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 52s - loss: 0.1011 - acc: 0.9675 - val_loss: 0.9237 - val_acc: 0.8056\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 41s - loss: 0.1025 - acc: 0.9671 - val_loss: 0.9245 - val_acc: 0.8053\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 41s - loss: 0.1015 - acc: 0.9673 - val_loss: 0.9368 - val_acc: 0.8055\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 43s - loss: 0.0975 - acc: 0.9684 - val_loss: 0.9269 - val_acc: 0.8087\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 55s - loss: 0.0944 - acc: 0.9692 - val_loss: 0.9133 - val_acc: 0.8044\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 45s - loss: 0.0910 - acc: 0.9701 - val_loss: 0.9206 - val_acc: 0.8119\n",
      "Test loss: 0.920594368088\n",
      "Test accuracy: 0.8119\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 30\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x2_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x2_test, y_test))\n",
    "score = model.evaluate(x2_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Observation:** As expected, the accuracy decreased dramatically when noise was introduced.  The accuracy for this model without noise was 98.5%, for the model with noisy data the accuracy dropped to 81.2%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv Net\n",
    "Trains a simple convnet on the MNIST dataset.\n",
    "Previous model got to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# insert random noise\n",
    "x2c_train = x_train * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
    "x2c_test = x_test * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12447b518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check out an image from training set\n",
    "plt.imshow(x2c_train[0].reshape(28,28)) #need to add in .reshape to the shape of the matrix to plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x2c_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "if backend.image_data_format() == 'channels_first':\n",
    "    x2c_train = x2c_train.reshape(x2c_train.shape[0], 1, img_rows, img_cols)\n",
    "    x2c_test = x2c_test.reshape(x2c_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x2c_train = x2c_train.reshape(x2c_train.shape[0], img_rows, img_cols, 1)\n",
    "    x2c_test = x2c_test.reshape(x2c_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x2c_train = x2c_train.astype('float32')\n",
    "x2c_test = x2c_test.astype('float32')\n",
    "x2c_train /= 255\n",
    "x2c_test /= 255\n",
    "print('x2c_train shape:', x2c_train.shape)\n",
    "print(x2c_train.shape[0], 'train samples')\n",
    "print(x2c_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 236s - loss: 0.6568 - acc: 0.7860 - val_loss: 0.1795 - val_acc: 0.94596580 - acc: 0.\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 260s - loss: 0.3330 - acc: 0.8971 - val_loss: 0.1225 - val_acc: 0.9619\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 232s - loss: 0.2675 - acc: 0.9168 - val_loss: 0.1081 - val_acc: 0.9656\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 232s - loss: 0.2352 - acc: 0.9286 - val_loss: 0.0974 - val_acc: 0.9697\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 234s - loss: 0.2114 - acc: 0.9358 - val_loss: 0.0907 - val_acc: 0.9728\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 237s - loss: 0.1956 - acc: 0.9389 - val_loss: 0.0919 - val_acc: 0.9704\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 278s - loss: 0.1819 - acc: 0.9434 - val_loss: 0.0855 - val_acc: 0.9740\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 246s - loss: 0.1728 - acc: 0.9455 - val_loss: 0.0866 - val_acc: 0.9747\n",
      "Test loss: 0.0865935281153\n",
      "Test accuracy: 0.9747\n"
     ]
    }
   ],
   "source": [
    "#changed parameters for model, changed optimizer, decreased batch size, decrease epochs, decrease neurons (to speed up processing)\n",
    "\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 8\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(16, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model2.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Dropout(0.25))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(64, activation='relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model2.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=Nadam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model2.fit(x2c_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x2c_test, y_test))\n",
    "score = model2.evaluate(x2c_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Observation:** Even though this CNN model performed worse than the model without noisy data (which had an accuracy score of 99.2%), with an accuracy of 97.5% it performed far better than our results for the multi-layer neural network.  This is likely because CNNs also flatten the images and the use of a drop out provides flexiblity on the network and finds the core elements which makes those numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part 3: Amplified Noise Data\n",
    "Vary the amount of noise (multiply `np.random.normal` by a factor) and keep track of the accuracy and loss (for training and validation) and plot these results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Neural Network with Amplified Noise Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add in the noise by multiplying by np.random.normal\n",
    "\n",
    "\n",
    "x3_train = (x_train * (10*np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)))\n",
    "x3_test = (x_test * (10*np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) train samples\n",
      "(10000, 784) test samples\n"
     ]
    }
   ],
   "source": [
    "x3_train = x3_train.reshape(60000, 784)\n",
    "x3_test = x3_test.reshape(10000, 784)\n",
    "\n",
    "x3_train = x3_train.astype('float32')\n",
    "x3_test = x3_test.astype('float32')\n",
    "x3_train /= 255\n",
    "x3_test /= 255\n",
    "print(x3_train.shape, 'train samples')\n",
    "print(x3_test.shape, 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1293f8908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check out an image from training set\n",
    "plt.imshow(x3_train[0].reshape(28,28)) #need to add in .reshape to the shape of the matrix to plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFOEHkiL8QFL/D81DL0jEh4KcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x129309748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check out an image from test set\n",
    "plt.imshow(x3_test[0].reshape(28,28)) #need to add in .reshape to the shape of the matrix to plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** The images are even more pixelated and there's less yellow spots than before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 932,362\n",
      "Trainable params: 932,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 46s - loss: 1.9615 - acc: 0.2853 - val_loss: 1.4548 - val_acc: 0.4693\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 39s - loss: 1.2662 - acc: 0.5443 - val_loss: 1.0722 - val_acc: 0.6179\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 40s - loss: 0.9679 - acc: 0.6542 - val_loss: 0.9384 - val_acc: 0.6681\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 39s - loss: 0.8151 - acc: 0.7110 - val_loss: 0.8707 - val_acc: 0.7010\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 39s - loss: 0.7042 - acc: 0.7494 - val_loss: 0.8354 - val_acc: 0.7136\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 39s - loss: 0.6297 - acc: 0.7767 - val_loss: 0.8137 - val_acc: 0.7220\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 39s - loss: 0.5662 - acc: 0.8010 - val_loss: 0.8055 - val_acc: 0.7251\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 39s - loss: 0.5261 - acc: 0.8180 - val_loss: 0.7734 - val_acc: 0.7478\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 46s - loss: 0.4834 - acc: 0.8332 - val_loss: 0.7997 - val_acc: 0.7482\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 45s - loss: 0.4544 - acc: 0.8441 - val_loss: 0.7867 - val_acc: 0.7589\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 46s - loss: 0.4173 - acc: 0.8569 - val_loss: 0.7500 - val_acc: 0.7572\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 44s - loss: 0.3947 - acc: 0.8646 - val_loss: 0.7864 - val_acc: 0.7540\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 45s - loss: 0.3768 - acc: 0.8711 - val_loss: 0.7700 - val_acc: 0.7693\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 49s - loss: 0.3618 - acc: 0.8761 - val_loss: 0.8035 - val_acc: 0.7660\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 50s - loss: 0.3479 - acc: 0.8828 - val_loss: 0.7473 - val_acc: 0.7760\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 49s - loss: 0.3263 - acc: 0.8900 - val_loss: 0.7740 - val_acc: 0.7814\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 50s - loss: 0.3229 - acc: 0.8894 - val_loss: 0.7808 - val_acc: 0.7779\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 45s - loss: 0.3077 - acc: 0.8964 - val_loss: 0.7517 - val_acc: 0.7807\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 52s - loss: 0.2967 - acc: 0.9007 - val_loss: 0.8133 - val_acc: 0.7793\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 52s - loss: 0.2914 - acc: 0.9028 - val_loss: 0.7904 - val_acc: 0.7883\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 44s - loss: 0.2779 - acc: 0.9059 - val_loss: 0.7921 - val_acc: 0.7833\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 42s - loss: 0.2660 - acc: 0.9107 - val_loss: 0.8037 - val_acc: 0.7945\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 42s - loss: 0.2643 - acc: 0.9108 - val_loss: 0.8208 - val_acc: 0.7842\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 41s - loss: 0.2615 - acc: 0.9123 - val_loss: 0.7696 - val_acc: 0.7958\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 42s - loss: 0.2486 - acc: 0.9175 - val_loss: 0.8394 - val_acc: 0.7897\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 41s - loss: 0.2440 - acc: 0.9179 - val_loss: 0.8226 - val_acc: 0.7927\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 42s - loss: 0.2392 - acc: 0.9210 - val_loss: 0.7922 - val_acc: 0.7977\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 42s - loss: 0.2388 - acc: 0.9215 - val_loss: 0.8279 - val_acc: 0.7918\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 43s - loss: 0.2235 - acc: 0.9259 - val_loss: 0.8100 - val_acc: 0.7962\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 44s - loss: 0.2252 - acc: 0.9249 - val_loss: 0.8186 - val_acc: 0.8019\n",
      "Test loss: 0.818587893331\n",
      "Test accuracy: 0.8019\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(512, activation='relu'))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(512, activation='sigmoid'))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model2.summary()\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model2.fit(x3_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x3_test, y_test))\n",
    "score = model2.evaluate(x3_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** With the adding in of a factor added to the random noise (amplifying the noise), the accuracy score decreased yet again from initally 98.5% (no noise), to 81.2% (random noise), to 80.2% (varied random noise). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv Net with Varied Noise Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x3c_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "#add in the noise by multiplying by np.random.normal\n",
    "x3c_train = (x_train * (10*np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)))\n",
    "x3c_test = (x_test * (10*np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)))\n",
    "\n",
    "if backend.image_data_format() == 'channels_first':\n",
    "    x3c_train = x3c_train.reshape(x3c_train.shape[0], 1, img_rows, img_cols)\n",
    "    x3c_test = x3c_test.reshape(x3c_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x3c_train = x3c_train.reshape(x3c_train.shape[0], img_rows, img_cols, 1)\n",
    "    x3c_test = x3c_test.reshape(x3c_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x3c_train = x3c_train.astype('float32')\n",
    "x3c_test = x3c_test.astype('float32')\n",
    "x3c_train /= 255\n",
    "x3c_test /= 255\n",
    "print('x3c_train shape:', x3c_train.shape)\n",
    "print(x3c_train.shape[0], 'train samples')\n",
    "print(x3c_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 238s - loss: 0.6931 - acc: 0.7738 - val_loss: 0.1658 - val_acc: 0.9539\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 258s - loss: 0.3318 - acc: 0.8986 - val_loss: 0.1376 - val_acc: 0.9566\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 234s - loss: 0.2642 - acc: 0.9197 - val_loss: 0.1153 - val_acc: 0.9633\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 214s - loss: 0.2300 - acc: 0.9308 - val_loss: 0.1011 - val_acc: 0.9696\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 222s - loss: 0.2031 - acc: 0.9386 - val_loss: 0.0977 - val_acc: 0.9697\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 210s - loss: 0.1863 - acc: 0.9427 - val_loss: 0.0838 - val_acc: 0.9734\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 211s - loss: 0.1692 - acc: 0.9481 - val_loss: 0.0852 - val_acc: 0.9739\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 206s - loss: 0.1566 - acc: 0.9520 - val_loss: 0.0796 - val_acc: 0.9744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12cb7ff60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 8\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Conv2D(16, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model3.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model3.add(Dropout(0.25))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(64, activation='relu'))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model3.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=Nadam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model3.fit(x3c_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x3c_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0795782163342\n",
      "Test accuracy: 0.9744\n"
     ]
    }
   ],
   "source": [
    "score = model3.evaluate(x3c_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Observation:** With the noisier data, the accuracy score decreased by 0.03 from 97.47% to 97.44%, only a slight difference. The loss score decreased though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
